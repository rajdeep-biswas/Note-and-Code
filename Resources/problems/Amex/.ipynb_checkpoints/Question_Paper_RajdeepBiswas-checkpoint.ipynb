{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a41a1fe",
   "metadata": {},
   "source": [
    "# AEXP ASSIGNMENT\n",
    "\n",
    "* Hi! This is a pre interview assignment to test your **programming** and **statistical** skills. \n",
    "* You have an hour to complete the test. \n",
    "* Time your test properly- **question 4 is a mandatory question and it has 4 parts all of them are mandatory**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3a78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d38dd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = load_diabetes()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "df = pd.DataFrame(data=dataset.data, columns=['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'])\n",
    "df[\"target\"] = dataset.target\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afcb15",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "### Create a new column in the dataframe which is the product of BMI and BP name it as prd_feat_1\n",
    "### Create another column target_percentile which takes prd_feat_1 as input and returns any one of the following\n",
    "\n",
    "* if value<=25th percentile then value=1 \n",
    "* if value>25th percentile and value<=50th percentile then value=2\n",
    "* if value>50th percentile and value<=75th percentile then value=3\n",
    "* if value>75th percentile then value=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924f64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prd_feat_1'] = df['bmi'] * df['bp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4f25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df['prd_feat_1']\n",
    "\n",
    "def target_percentile(row):\n",
    "    if row['prd_feat_1'] <= col.quantile(0.1):\n",
    "        val = 1\n",
    "    elif row['prd_feat_1'] > col.quantile(0.25) and row['prd_feat_1'] <= col.quantile(0.5):\n",
    "        val = 2\n",
    "    elif row['prd_feat_1'] > col.quantile(0.5) and row['prd_feat_1'] <= col.quantile(0.75):\n",
    "        val = 3\n",
    "    else:\n",
    "        val = 4\n",
    "    return val\n",
    "\n",
    "df['target_percentile'] = df.apply(target_percentile, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea5d675",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "### Split the data into test and train dataset keeping the distribution of the target_percentile similar for both of them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3ec149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cols = list(df.columns)\n",
    "X_cols.remove('target_percentile')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[X_cols], df[['target_percentile']], test_size=0.33, stratify=df['target_percentile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "instant-complement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "      <th>prd_feat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.027178</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.049840</td>\n",
       "      <td>-0.055018</td>\n",
       "      <td>-0.002945</td>\n",
       "      <td>0.040648</td>\n",
       "      <td>-0.058127</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>-0.052959</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.023677</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.059541</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.042848</td>\n",
       "      <td>-0.043589</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.015998</td>\n",
       "      <td>0.040343</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-0.009147</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.002228</td>\n",
       "      <td>0.079612</td>\n",
       "      <td>0.070084</td>\n",
       "      <td>0.033914</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.026714</td>\n",
       "      <td>0.081764</td>\n",
       "      <td>142.0</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.067268</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.054707</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.075870</td>\n",
       "      <td>-0.082106</td>\n",
       "      <td>0.048640</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.104630</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>0.047224</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.033249</td>\n",
       "      <td>-0.059067</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>0.024574</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.048362</td>\n",
       "      <td>-0.030072</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>-0.050428</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>0.047224</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.016281</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.063330</td>\n",
       "      <td>-0.057314</td>\n",
       "      <td>-0.057983</td>\n",
       "      <td>-0.048912</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.059473</td>\n",
       "      <td>-0.067351</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.003630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.012780</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.060618</td>\n",
       "      <td>0.052858</td>\n",
       "      <td>0.047965</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.003204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.019913</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>0.023198</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.067048</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.023645</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-0.000120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "107  0.027178 -0.044642  0.049840 -0.055018 -0.002945  0.040648 -0.058127   \n",
       "27  -0.023677 -0.044642  0.059541 -0.040099 -0.042848 -0.043589  0.011824   \n",
       "309 -0.009147  0.050680  0.001339 -0.002228  0.079612  0.070084  0.033914   \n",
       "187 -0.067268 -0.044642 -0.054707 -0.026328 -0.075870 -0.082106  0.048640   \n",
       "210  0.009016 -0.044642  0.014272  0.014987  0.054845  0.047224  0.070730   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "178  0.041708 -0.044642 -0.008362 -0.026328  0.024574  0.016222  0.070730   \n",
       "415 -0.005515 -0.044642  0.008883 -0.050428  0.025950  0.047224 -0.043401   \n",
       "34   0.016281 -0.044642 -0.063330 -0.057314 -0.057983 -0.048912  0.008142   \n",
       "249 -0.012780 -0.044642  0.060618  0.052858  0.047965  0.029375 -0.017629   \n",
       "111  0.019913 -0.044642  0.004572 -0.026328  0.023198  0.010273  0.067048   \n",
       "\n",
       "           s4        s5        s6  target  prd_feat_1  \n",
       "107  0.052759 -0.052959 -0.005220   144.0   -0.002742  \n",
       "27  -0.039493 -0.015998  0.040343    85.0   -0.002388  \n",
       "309 -0.002592  0.026714  0.081764   142.0   -0.000003  \n",
       "187 -0.076395 -0.086829 -0.104630   143.0    0.001440  \n",
       "210 -0.039493 -0.033249 -0.059067   191.0    0.000214  \n",
       "..        ...       ...       ...     ...         ...  \n",
       "178 -0.039493 -0.048362 -0.030072    81.0    0.000220  \n",
       "415  0.071210  0.014823  0.003064   174.0   -0.000448  \n",
       "34  -0.039493 -0.059473 -0.067351    65.0    0.003630  \n",
       "249  0.034309  0.070211  0.007207   215.0    0.003204  \n",
       "111 -0.039493 -0.023645 -0.046641    59.0   -0.000120  \n",
       "\n",
       "[296 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb10d3f",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "### We have to design a deep learning system to identify brain tumor through CT scan images\n",
    "\n",
    "#### What do you think might be the most appropriate evaluation metric and why: Accuracy, Precision, Recall, F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-wiring",
   "metadata": {},
   "source": [
    "### Answer\n",
    "1. Since accuracy just measures how many observations were correctly classified, it might not be the most reliable metric.\n",
    "2. Precision measures the correctness of all positive detections regarding how many of them are true positives vs how many are false positives, more reliable than accuracy but we can still improve.\n",
    "3. Recall, similarly, measures how much our model is correctly identifying the true positives, can be used interchangeably with precision but not yet best.\n",
    "4. **F1 score is the harmonic mean between precision and recall, so that must be the most appropriate evaluation metric that we should use.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97497088",
   "metadata": {},
   "source": [
    "# Question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2871ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** DO NOT CHANGE THIS PART ***\n",
    "\n",
    "string_1 = '''Hist’’^ory also includes [6] the academic discipline which uses narrative to describe, examine, question, and analyze past events, and investigate their patterns [6] of cause and effect.[6][7] Historians often debate which narrati[10]ve best explains an event, as well as the signific’’^ance of[6] different causes and effects. Histo’’^rians also debate the [6]nature of history as an end in itself, as well as its usefulness to give perspective on the problems of the present.[6][8][9][10]'''\n",
    "string_2 = '''Stories common to a particular cultu’’^re, but not supported by external sources (such as the tales surrounding King Arthur), are usually classified as cultural herit’’^age or legends.[11][12] History differs from myth in that it is supported by evidence. However, ancient cultural influences have helped spawn variant interpretations of the nature of History which have evo’’^lved over the [11] [11] [11] centuries and continue to change today. The modern study of history is wide-ranging, and includes the study of specific regions and the study of certain topical or thematic elements of historical investigation. History is often taught as [11][ part of primary and secondary education, and the academic study of history is a major discipline in university studies.'''\n",
    "string_3  = '''Stories common to a particular culture, but not supported by external sources (such as the tales surrounding King Arthur), are usually classified as cultural heritage or legends.[11][12] History differs from myth in that it is supported by evidence. However, ancient cultural influences have helped spawn variant interpretations of the nature of history which have evolved over [14][15]  [14][15]  the centuries and continue to change today. The modern study of history is wide-ranging, and includes the study of specific regions and the study of certain topical or thematic elements of historical investigation. Herodotus, a 5th-century BC Greek historian, is often considered the \"father of history\" in the Western tradition,[13] although he has also been criticized as the \"father of lies\".[14][15] Along with his contemporary Thucydides, he helped form the foundations for the modern study of past events and societies. Their works continue to be read today, and the gap between the culture-focused Herodotus and the military-focused Thucydides remains a point of contention or approach in modern historical writing.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-basics",
   "metadata": {},
   "source": [
    "### Part 1 remove punctuations and special characters  from the 3 strings and create a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [string_1, string_2, string_3]\n",
    "wordlist = []\n",
    "remove_list = '-’^,.\"]()'\n",
    "\n",
    "for string in strings:\n",
    "    for word in string.split(' '):\n",
    "        for ch in remove_list:\n",
    "            if '[' in word:\n",
    "                word = word.replace(word[word.index('['): word.rindex(']')].strip(), '')\n",
    "            else:\n",
    "                word = word.replace(ch, '')\n",
    "        if word:\n",
    "            wordlist.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "combined-canal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history',\n",
       " 'also',\n",
       " 'includes',\n",
       " 'the',\n",
       " 'academic',\n",
       " 'discipline',\n",
       " 'which',\n",
       " 'uses',\n",
       " 'narrative',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'examine',\n",
       " 'question',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'past',\n",
       " 'events',\n",
       " 'and',\n",
       " 'investigate',\n",
       " 'their',\n",
       " 'patterns',\n",
       " 'of',\n",
       " 'cause',\n",
       " 'and',\n",
       " 'effect',\n",
       " 'historians',\n",
       " 'often',\n",
       " 'debate',\n",
       " 'which',\n",
       " 'narrative',\n",
       " 'best',\n",
       " 'explains',\n",
       " 'an',\n",
       " 'event',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'significance',\n",
       " 'of',\n",
       " 'different',\n",
       " 'causes',\n",
       " 'and',\n",
       " 'effects',\n",
       " 'historians',\n",
       " 'also',\n",
       " 'debate',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'history',\n",
       " 'as',\n",
       " 'an',\n",
       " 'end',\n",
       " 'in',\n",
       " 'itself',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'its',\n",
       " 'usefulness',\n",
       " 'to',\n",
       " 'give',\n",
       " 'perspective',\n",
       " 'on',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'the',\n",
       " 'present',\n",
       " 'stories',\n",
       " 'common',\n",
       " 'to',\n",
       " 'a',\n",
       " 'particular',\n",
       " 'culture',\n",
       " 'but',\n",
       " 'not',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'external',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'tales',\n",
       " 'surrounding',\n",
       " 'king',\n",
       " 'arthur',\n",
       " 'are',\n",
       " 'usually',\n",
       " 'classified',\n",
       " 'as',\n",
       " 'cultural',\n",
       " 'heritage',\n",
       " 'or',\n",
       " 'legends',\n",
       " 'history',\n",
       " 'differs',\n",
       " 'from',\n",
       " 'myth',\n",
       " 'in',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'evidence',\n",
       " 'however',\n",
       " 'ancient',\n",
       " 'cultural',\n",
       " 'influences',\n",
       " 'have',\n",
       " 'helped',\n",
       " 'spawn',\n",
       " 'variant',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'history',\n",
       " 'which',\n",
       " 'have',\n",
       " 'evolved',\n",
       " 'over',\n",
       " 'the',\n",
       " 'centuries',\n",
       " 'and',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'change',\n",
       " 'today',\n",
       " 'the',\n",
       " 'modern',\n",
       " 'study',\n",
       " 'of',\n",
       " 'history',\n",
       " 'is',\n",
       " 'wideranging',\n",
       " 'and',\n",
       " 'includes',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'specific',\n",
       " 'regions',\n",
       " 'and',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'certain',\n",
       " 'topical',\n",
       " 'or',\n",
       " 'thematic',\n",
       " 'elements',\n",
       " 'of',\n",
       " 'historical',\n",
       " 'investigation',\n",
       " 'history',\n",
       " 'is',\n",
       " 'often',\n",
       " 'taught',\n",
       " 'as',\n",
       " '][',\n",
       " 'part',\n",
       " 'of',\n",
       " 'primary',\n",
       " 'and',\n",
       " 'secondary',\n",
       " 'education',\n",
       " 'and',\n",
       " 'the',\n",
       " 'academic',\n",
       " 'study',\n",
       " 'of',\n",
       " 'history',\n",
       " 'is',\n",
       " 'a',\n",
       " 'major',\n",
       " 'discipline',\n",
       " 'in',\n",
       " 'university',\n",
       " 'studies',\n",
       " 'stories',\n",
       " 'common',\n",
       " 'to',\n",
       " 'a',\n",
       " 'particular',\n",
       " 'culture',\n",
       " 'but',\n",
       " 'not',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'external',\n",
       " 'sources',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'tales',\n",
       " 'surrounding',\n",
       " 'king',\n",
       " 'arthur',\n",
       " 'are',\n",
       " 'usually',\n",
       " 'classified',\n",
       " 'as',\n",
       " 'cultural',\n",
       " 'heritage',\n",
       " 'or',\n",
       " 'legends',\n",
       " 'history',\n",
       " 'differs',\n",
       " 'from',\n",
       " 'myth',\n",
       " 'in',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'evidence',\n",
       " 'however',\n",
       " 'ancient',\n",
       " 'cultural',\n",
       " 'influences',\n",
       " 'have',\n",
       " 'helped',\n",
       " 'spawn',\n",
       " 'variant',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'history',\n",
       " 'which',\n",
       " 'have',\n",
       " 'evolved',\n",
       " 'over',\n",
       " 'the',\n",
       " 'centuries',\n",
       " 'and',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'change',\n",
       " 'today',\n",
       " 'the',\n",
       " 'modern',\n",
       " 'study',\n",
       " 'of',\n",
       " 'history',\n",
       " 'is',\n",
       " 'wideranging',\n",
       " 'and',\n",
       " 'includes',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'specific',\n",
       " 'regions',\n",
       " 'and',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'certain',\n",
       " 'topical',\n",
       " 'or',\n",
       " 'thematic',\n",
       " 'elements',\n",
       " 'of',\n",
       " 'historical',\n",
       " 'investigation',\n",
       " 'herodotus',\n",
       " 'a',\n",
       " '5thcentury',\n",
       " 'bc',\n",
       " 'greek',\n",
       " 'historian',\n",
       " 'is',\n",
       " 'often',\n",
       " 'considered',\n",
       " 'the',\n",
       " 'father',\n",
       " 'of',\n",
       " 'history',\n",
       " 'in',\n",
       " 'the',\n",
       " 'western',\n",
       " 'tradition',\n",
       " 'although',\n",
       " 'he',\n",
       " 'has',\n",
       " 'also',\n",
       " 'been',\n",
       " 'criticized',\n",
       " 'as',\n",
       " 'the',\n",
       " 'father',\n",
       " 'of',\n",
       " 'lies',\n",
       " 'along',\n",
       " 'with',\n",
       " 'his',\n",
       " 'contemporary',\n",
       " 'thucydides',\n",
       " 'he',\n",
       " 'helped',\n",
       " 'form',\n",
       " 'the',\n",
       " 'foundations',\n",
       " 'for',\n",
       " 'the',\n",
       " 'modern',\n",
       " 'study',\n",
       " 'of',\n",
       " 'past',\n",
       " 'events',\n",
       " 'and',\n",
       " 'societies',\n",
       " 'their',\n",
       " 'works',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'be',\n",
       " 'read',\n",
       " 'today',\n",
       " 'and',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'culturefocused',\n",
       " 'herodotus',\n",
       " 'and',\n",
       " 'the',\n",
       " 'militaryfocused',\n",
       " 'thucydides',\n",
       " 'remains',\n",
       " 'a',\n",
       " 'point',\n",
       " 'of',\n",
       " 'contention',\n",
       " 'or',\n",
       " 'approach',\n",
       " 'in',\n",
       " 'modern',\n",
       " 'historical',\n",
       " 'writing']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-pakistan",
   "metadata": {},
   "source": [
    "### Part 2 make everything lowercase within the list from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attached-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done in line 13 of above code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-generic",
   "metadata": {},
   "source": [
    "### Part 3 remove prepositions from the strings from above list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simplified-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "weighted-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mature-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(' '.join(wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "special-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_preps = set()\n",
    "\n",
    "for token in doc:\n",
    "    if token.dep_ == 'prep':\n",
    "        found_preps.add(str(token))\n",
    "        \n",
    "found_preps = list(found_preps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "interpreted-memphis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['on',\n",
       " 'of',\n",
       " 'along',\n",
       " 'over',\n",
       " 'from',\n",
       " 'for',\n",
       " 'to',\n",
       " 'between',\n",
       " 'with',\n",
       " 'in',\n",
       " 'as']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_preps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polyphonic-adams",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "animal-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [word for word in wordlist if word not in found_preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "offshore-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294 False False\n"
     ]
    }
   ],
   "source": [
    "# checks whether length reduced and rigorous word existence checking\n",
    "print(len(wordlist), 'over' in wordlist, 'from' in wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5398c50e",
   "metadata": {},
   "source": [
    " ###  Part 4 From the list you created above count the number of occurances following phrase for each string\n",
    " \n",
    " #### **\"history evolved centuries\"** \n",
    " \n",
    " ### The above phrase can occur more than once in the above strings in the same sequence given there can be upto **4 words** between each of the them.\n",
    "\n",
    "**ex-**  \n",
    "* <start>.... history **w1** **w2** evolved **w1** **w2** **w3** **w4** centuries .... <end>\n",
    "    \n",
    "* <start>.... history **w1** evolved centuries .... <end>\n",
    "    \n",
    "* <start>.... history evolved centuries ....<end>\n",
    "\n",
    "* <start>.... history **w1 w2**  evolved **w1** centuries ....<end>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a3a6ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history also includes the academic discipline which uses narrative describe examine question and analyze past events and investigate their patterns cause and effect historians often debate which narrative best explains an event well the significance different causes and effects historians also debate the nature history an end itself well its usefulness give perspective the problems the present stories common a particular culture but not supported by external sources such the tales surrounding king arthur are usually classified cultural heritage or legends history differs myth that it is supported by evidence however ancient cultural influences have helped spawn variant interpretations the nature history which have evolved the centuries and continue change today the modern study history is wideranging and includes the study specific regions and the study certain topical or thematic elements historical investigation history is often taught ][ part primary and secondary education and the academic study history is a major discipline university studies stories common a particular culture but not supported by external sources such the tales surrounding king arthur are usually classified cultural heritage or legends history differs myth that it is supported by evidence however ancient cultural influences have helped spawn variant interpretations the nature history which have evolved the centuries and continue change today the modern study history is wideranging and includes the study specific regions and the study certain topical or thematic elements historical investigation herodotus a 5thcentury bc greek historian is often considered the father history the western tradition although he has also been criticized the father lies his contemporary thucydides he helped form the foundations the modern study past events and societies their works continue be read today and the gap the culturefocused herodotus and the militaryfocused thucydides remains a point contention or approach modern historical writing\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b165e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "found_idx = -1\n",
    "\n",
    "for i in range(len(wordlist)):\n",
    "    \n",
    "    if wordlist[i] == 'history':\n",
    "        found_idx = i\n",
    "        \n",
    "    elif wordlist[i] == 'evolved':\n",
    "        if i - found_idx <= 4:\n",
    "            found_idx = i\n",
    "        else:\n",
    "            found_idx =- 1\n",
    "            \n",
    "    elif wordlist[i] == 'centuries':\n",
    "        if i - found_idx <= 4:\n",
    "            count += 1\n",
    "            found_idx = i\n",
    "        else:\n",
    "            found_idx =- 1\n",
    "            \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-rehabilitation",
   "metadata": {},
   "source": [
    "### Answer -\n",
    "There are **two** such occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201e1a7",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc18b98",
   "metadata": {},
   "source": [
    "#### *  What is the time complexity of your algo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-description",
   "metadata": {},
   "source": [
    "#### Answer: The time complexity of my algorithm is linear i.e. O(n) since there is only one single pass through the entire array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85908e2d",
   "metadata": {},
   "source": [
    "#### *  Can you design it in linear time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-norwegian",
   "metadata": {},
   "source": [
    "#### It is already in linear time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d2eda",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf7745",
   "metadata": {},
   "source": [
    "### P1 and P2 are two persons: \n",
    "    \n",
    "#### P1 thinks even numbers are lucky for him and randomly rolls a dice once and cuts a square from a sheet of paper with side value = value on dice only when there is an even number\n",
    "\n",
    "#### P2 who doesn't believe in luck however rolls the dice twice and cuts a rectangle with length as first roll value and breadth as second roll value\n",
    "\n",
    "* On an average, what is the size of area end up cutting by each person?\n",
    "* Are they equal? \n",
    "* If not then who cuts the larger area and why?\n",
    "(Hint: structure the problem algorithmically)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-hobby",
   "metadata": {},
   "source": [
    "### Solution: let's generate a sample size of 1000 experiments for each and find out by repeating the experiment 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3ffbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def generate_results():\n",
    "    dice = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    p1_rolls = []\n",
    "    p2_rolls = []\n",
    "\n",
    "    for i in range(1000):\n",
    "        roll1 = random.choice(dice)\n",
    "        if not roll1 % 2:\n",
    "            p1_rolls.append(roll1 ** 2)\n",
    "\n",
    "        roll2 = random.choice(dice)\n",
    "        roll3 = random.choice(dice)\n",
    "        p2_rolls.append(roll2 * roll3)\n",
    "        \n",
    "    return sum(p1_rolls) / len(p1_rolls), sum(p2_rolls) / len(p2_rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cb2472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18.307692307692307, 12.308)\n"
     ]
    }
   ],
   "source": [
    "print(generate_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "artificial-denial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.531827515400412, 12.628)\n"
     ]
    }
   ],
   "source": [
    "print(generate_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intellectual-customs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17.852295409181636, 12.538)\n"
     ]
    }
   ],
   "source": [
    "print(generate_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cordless-prerequisite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18.01926782273603, 12.414)\n"
     ]
    }
   ],
   "source": [
    "print(generate_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "regulated-bargain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18.163672654690618, 12.588)\n"
     ]
    }
   ],
   "source": [
    "print(generate_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-sucking",
   "metadata": {},
   "source": [
    "### From the obtained results it is clear that P1 with even numbered square side values is always the winner by a large margin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
